{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3e084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e15fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Llama3 model\n",
    "llm = ChatOllama(model=\"mistral:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4479e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(json_path):\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    df = pd.json_normalize(data)\n",
    "    \n",
    "    # Ensure correct numeric types\n",
    "    numeric_cols = ['age', 'sysBP', 'diaBP', 'totChol', 'BMI', 'glucose',\n",
    "                   'currentSmoker', 'diabetes', 'male', 'BPMeds']\n",
    "    for col in numeric_cols:\n",
    "        if col in df:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Fill missing values with medians (better than 0)\n",
    "    for col in numeric_cols:\n",
    "        if col in df:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe50d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_predict(row):\n",
    "    # Extract and format features\n",
    "    features = {\n",
    "        'age': int(row['age']),\n",
    "        'bp': f\"{int(row['sysBP'])}/{int(row['diaBP'])}\",\n",
    "        'chol': int(row['totChol']),\n",
    "        'smoker': bool(row['currentSmoker']),\n",
    "        'bmi': float(row['BMI']),\n",
    "        'diabetes': bool(row['diabetes'])\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"As a cardiology specialist, evaluate this patient's 10-year CHD risk:\n",
    "\n",
    "Patient Data:\n",
    "- Age: {features['age']}\n",
    "- Blood Pressure: {features['bp']} mmHg\n",
    "- Cholesterol: {features['chol']} mg/dL\n",
    "- Smoker: {'Yes' if features['smoker'] else 'No'}\n",
    "- BMI: {features['bmi']:.1f}\n",
    "- Diabetes: {'Yes' if features['diabetes'] else 'No'}\n",
    "\n",
    "Analysis Guidelines:\n",
    "1. Calculate Framingham Risk Score:\n",
    "   - Age >50 (1 point)\n",
    "   - SBP >140 or DBP >90 (1 point)\n",
    "   - Cholesterol >240 (1 point)\n",
    "   - Smoking (1 point)\n",
    "   - BMI >30 (1 point)\n",
    "   - Diabetes (2 points)\n",
    "2. Score â‰¥3 indicates high risk\n",
    "\n",
    "Decision:\n",
    "- Only respond with '0' (low risk) or '1' (high risk)\n",
    "- No explanations needed\n",
    "\n",
    "Your prediction:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": \"You are a cardiac risk assessment AI. Follow the instructions precisely.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ])\n",
    "        return int(response.content.strip()[:1])  # Takes first character only\n",
    "    except:\n",
    "        return 0  # Fallback to low risk on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f3a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.00%\n",
      "\n",
      "Sample predictions:\n",
      "   Actual  Predicted  Match\n",
      "0       0          0   True\n",
      "1       0          1  False\n",
      "2       0          1  False\n",
      "3       1          1   True\n",
      "4       0          1  False\n",
      "5       0          1  False\n",
      "6       1          1   True\n",
      "7       0          1  False\n",
      "8       0          0   True\n",
      "9       0          1  False\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = load_and_prepare_data('framingham.json')\n",
    "    \n",
    "    # Prepare test set\n",
    "    test_df = df.iloc[:20]  # First 20 samples\n",
    "    features = test_df.drop(columns=['TenYearCHD'])\n",
    "    true_labels = test_df['TenYearCHD']\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = features.apply(enhanced_predict, axis=1)\n",
    "    predictions = predictions.astype(int)\n",
    "    true_labels = true_labels.astype(int)\n",
    "    # Calculate accuracy\n",
    "    accuracy = (predictions == true_labels).mean()\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    # Debug output\n",
    "    print(\"\\nSample predictions:\")\n",
    "    print(pd.DataFrame({\n",
    "        'Actual': true_labels,\n",
    "        'Predicted': predictions,\n",
    "        'Match': true_labels == predictions\n",
    "    }).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
