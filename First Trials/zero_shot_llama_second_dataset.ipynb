{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1be6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from langchain_ollama import ChatOllama\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c0af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "target = df['stroke']\n",
    "features = df.drop(columns=['stroke', 'id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f231e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sample = features.head(50)\n",
    "target_sample = target.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920e8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.1,  # Lower temperature for faster, more consistent responses\n",
    "    num_ctx=512,  # Reduced context window for faster processing\n",
    "    num_thread=4  # Utilize multiple threads for inference\n",
    ")\n",
    "\n",
    "def llm_predict(row):\n",
    "    prompt = f\"\"\"You are a highly experienced medical expert specialized in stroke prediction.\n",
    "\n",
    "\n",
    "Given a patient's medical information, predict whether the patient is likely to experience a stroke.\n",
    "\n",
    "\n",
    "Here is the patient's information:\n",
    "- Gender: {row['gender']}\n",
    "- Age: {row['age']}\n",
    "- Hypertension (0: No, 1: Yes): {row['hypertension']}\n",
    "- Heart Disease (0: No, 1: Yes): {row['heart_disease']}\n",
    "- Ever Married (Yes/No): {row['ever_married']}\n",
    "- Work Type (Private, Self-employed, Govt_job, Children, Never_worked): {row['work_type']}\n",
    "- Residence Type (Urban/Rural): {row['Residence_type']}\n",
    "- Average Glucose Level: {row['avg_glucose_level']}\n",
    "- BMI (Body Mass Index): {row['bmi']}\n",
    "- Smoking Status (formerly smoked / never smoked / smokes / unknown): {row['smoking_status']}\n",
    "\n",
    "\n",
    "Based on this information, please answer strictly with one of the following two options:\n",
    "- \"Stroke\"\n",
    "- \"No Stroke\"\n",
    "\n",
    "\n",
    "Do not add any extra explanation. Only return \"Stroke\" or \"No Stroke\".\"\"\"\n",
    "   \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical AI specialized in predicting stroke risk. Assess based only on the provided data.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "   \n",
    "    output = response.content.strip().lower()\n",
    "    return 1 if \"stroke\" in output and \"no\" not in output else 0\n",
    "\n",
    "def predict_with_improved_approach(row):\n",
    "    \"\"\"Zero-shot with medical guidelines\"\"\"\n",
    "    prompt = f\"\"\"As a stroke prediction specialist, analyze the following patient data:\n",
    "\n",
    "Patient Information:\n",
    "- Gender: {row['gender']}\n",
    "- Age: {int(row['age'])}\n",
    "- Hypertension: {row['hypertension']}\n",
    "- Heart Disease: {row['heart_disease']}\n",
    "- Ever Married: {row['ever_married']}\n",
    "- Work Type: {row['work_type']}\n",
    "- Residence Type: {row['Residence_type']}\n",
    "- Average Glucose Level: {row['avg_glucose_level']:.2f}\n",
    "- BMI: {row['bmi']:.1f}\n",
    "- Smoking Status: {row['smoking_status']}\n",
    "\n",
    "Medical Stroke Risk Factors:\n",
    "1. Advanced age (especially >65)\n",
    "2. Presence of hypertension\n",
    "3. History of heart disease\n",
    "4. High glucose levels (>140 mg/dL)\n",
    "5. High BMI (>30)\n",
    "6. Smoking history\n",
    "\n",
    "Your assessment:\n",
    "1. Systematically evaluate each risk factor above\n",
    "2. Indicate the risk level for each factor\n",
    "3. Conduct an overall risk assessment\n",
    "4. Answer with ONLY \"Stroke\" or \"No Stroke\"\n",
    "\n",
    "Your prediction:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"You are a stroke risk prediction specialist. Answer with ONLY 'Stroke' or 'No Stroke', nothing else.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    \n",
    "    output = response.content.strip().lower()\n",
    "    if \"stroke\" in output and not any(neg in output for neg in [\"no stroke\", \"no-stroke\", \"not stroke\"]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99292df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_predict(row):\n",
    "    \"\"\"Efficient approach with focused medical guidelines\"\"\"\n",
    "    prompt = f\"\"\"As a stroke specialist, analyze:\n",
    "\n",
    "Patient Information:\n",
    "- Age: {int(row['age'])} | Gender: {row['gender']}\n",
    "- Hypertension: {row['hypertension']} | Heart Disease: {row['heart_disease']}\n",
    "- Glucose: {row['avg_glucose_level']:.1f} | BMI: {row['bmi']:.1f}\n",
    "- Smoking: {row['smoking_status']}\n",
    "\n",
    "Risk factors analysis:\n",
    "- Age >65: {int(row['age']) > 65}\n",
    "- Hypertension: {row['hypertension'] == 1}\n",
    "- Heart Disease: {row['heart_disease'] == 1}\n",
    "- High Glucose (>140): {row['avg_glucose_level'] > 140}\n",
    "- High BMI (>30): {row['bmi'] > 30}\n",
    "- Smoking risk: {\"Yes\" if row['smoking_status'] in [\"formerly smoked\", \"smokes\"] else \"No\"}\n",
    "\n",
    "Based on these factors, answer ONLY \"Stroke\" or \"No Stroke\".\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"You are a stroke risk specialist. Answer with ONLY 'Stroke' or 'No Stroke'.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    \n",
    "    output = response.content.strip().lower()\n",
    "    return 1 if \"stroke\" in output and not any(neg in output for neg in [\"no stroke\", \"no-stroke\", \"not stroke\"]) else 0\n",
    "\n",
    "def batch_predict(dataframe, batch_size=5):\n",
    "    \"\"\"Process predictions in parallel batches\"\"\"\n",
    "    predictions = []\n",
    "    total = len(dataframe)\n",
    "    \n",
    "    # Process in batches using multiple threads\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = dataframe.iloc[i:min(i+batch_size, total)]\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "            batch_results = list(executor.map(efficient_predict, [row for _, row in batch.iterrows()]))\n",
    "            \n",
    "        predictions.extend(batch_results)\n",
    "        print(f\"Processed {min(i+batch_size, total)}/{total} samples\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbf99579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5/50 samples\n",
      "Processed 10/50 samples\n",
      "Processed 15/50 samples\n",
      "Processed 20/50 samples\n",
      "Processed 25/50 samples\n",
      "Processed 30/50 samples\n",
      "Processed 35/50 samples\n",
      "Processed 40/50 samples\n",
      "Processed 45/50 samples\n",
      "Processed 50/50 samples\n"
     ]
    }
   ],
   "source": [
    "#preds = features_sample.apply(llm_predict, axis=1)\n",
    "#preds = features_sample.apply(predict_with_improved_approach, axis=1)\n",
    "preds = batch_predict(features_sample, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3454cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(target_sample, preds)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a20c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
