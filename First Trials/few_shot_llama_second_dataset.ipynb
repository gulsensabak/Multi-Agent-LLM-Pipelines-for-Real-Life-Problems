{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7567509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing case 1/20: Actual=1, Predicted=1\n",
      "Processing case 2/20: Actual=1, Predicted=0\n",
      "Processing case 3/20: Actual=1, Predicted=0\n",
      "Processing case 4/20: Actual=1, Predicted=1\n",
      "Processing case 5/20: Actual=1, Predicted=0\n",
      "Processing case 6/20: Actual=1, Predicted=1\n",
      "Processing case 7/20: Actual=1, Predicted=0\n",
      "Processing case 8/20: Actual=1, Predicted=0\n",
      "Processing case 9/20: Actual=1, Predicted=0\n",
      "Processing case 10/20: Actual=1, Predicted=0\n",
      "Processing case 11/20: Actual=0, Predicted=0\n",
      "Processing case 12/20: Actual=0, Predicted=1\n",
      "Processing case 13/20: Actual=0, Predicted=0\n",
      "Processing case 14/20: Actual=0, Predicted=0\n",
      "Processing case 15/20: Actual=0, Predicted=0\n",
      "Processing case 16/20: Actual=0, Predicted=0\n",
      "Processing case 17/20: Actual=0, Predicted=0\n",
      "Processing case 18/20: Actual=0, Predicted=0\n",
      "Processing case 19/20: Actual=0, Predicted=0\n",
      "Processing case 20/20: Actual=0, Predicted=0\n",
      "\n",
      "Accuracy: 60.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69        10\n",
      "           1       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.66      0.60      0.56        20\n",
      "weighted avg       0.66      0.60      0.56        20\n",
      "\n",
      "\n",
      "Detailed Comparison:\n",
      "      Actual  Predicted  Match\n",
      "196        1          1   True\n",
      "152        1          0  False\n",
      "224        1          0  False\n",
      "144        1          1   True\n",
      "29         1          0  False\n",
      "17         1          1   True\n",
      "141        1          0  False\n",
      "127        1          0  False\n",
      "95         1          0  False\n",
      "117        1          0  False\n",
      "2008       0          0   True\n",
      "929        0          1  False\n",
      "2739       0          0   True\n",
      "4723       0          0   True\n",
      "3952       0          0   True\n",
      "1491       0          0   True\n",
      "1758       0          0   True\n",
      "2634       0          0   True\n",
      "3082       0          0   True\n",
      "4018       0          0   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize Llama3 or Mistral with optimized settings\n",
    "llm = ChatOllama(\n",
    "    model=\"mistral:latest\",\n",
    "    temperature=0.1,  # Lower temperature for more consistent medical reasoning\n",
    "    top_p=0.95,\n",
    "    repeat_penalty=1.2\n",
    ")\n",
    "\n",
    "def load_data(csv_path):\n",
    "    \"\"\"Load and prepare data from CSV\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce')\n",
    "    df['bmi'].fillna(df['bmi'].median(), inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_few_shot_examples(df):\n",
    "    \"\"\"Select and format balanced examples\"\"\"\n",
    "    # Find a positive case (stroke=1)\n",
    "    positive_example = df[df['stroke'] == 1].iloc[0]\n",
    "    # Find a negative case (stroke=0)\n",
    "    negative_example = df[df['stroke'] == 0].iloc[0]\n",
    "    \n",
    "    examples_str = (\n",
    "        f\"Example Patient 1 (Stroke):\\n\"\n",
    "        f\"- Gender: {positive_example['gender']}\\n\"\n",
    "        f\"- Age: {int(positive_example['age'])}\\n\"\n",
    "        f\"- Hypertension: {positive_example['hypertension']}\\n\"\n",
    "        f\"- Heart Disease: {positive_example['heart_disease']}\\n\"\n",
    "        f\"- Ever Married: {positive_example['ever_married']}\\n\"\n",
    "        f\"- Work Type: {positive_example['work_type']}\\n\"\n",
    "        f\"- Residence Type: {positive_example['Residence_type']}\\n\"\n",
    "        f\"- Average Glucose Level: {positive_example['avg_glucose_level']:.2f}\\n\"\n",
    "        f\"- BMI: {positive_example['bmi']:.1f}\\n\"\n",
    "        f\"- Smoking Status: {positive_example['smoking_status']}\\n\"\n",
    "        f\"Stroke Status: Stroke\\n\\n\"\n",
    "        \n",
    "        f\"Example Patient 2 (No Stroke):\\n\"\n",
    "        f\"- Gender: {negative_example['gender']}\\n\"\n",
    "        f\"- Age: {int(negative_example['age'])}\\n\"\n",
    "        f\"- Hypertension: {negative_example['hypertension']}\\n\"\n",
    "        f\"- Heart Disease: {negative_example['heart_disease']}\\n\"\n",
    "        f\"- Ever Married: {negative_example['ever_married']}\\n\"\n",
    "        f\"- Work Type: {negative_example['work_type']}\\n\"\n",
    "        f\"- Residence Type: {negative_example['Residence_type']}\\n\"\n",
    "        f\"- Average Glucose Level: {negative_example['avg_glucose_level']:.2f}\\n\"\n",
    "        f\"- BMI: {negative_example['bmi']:.1f}\\n\"\n",
    "        f\"- Smoking Status: {negative_example['smoking_status']}\\n\"\n",
    "        f\"Stroke Status: No Stroke\"\n",
    "    )\n",
    "    return examples_str, [positive_example.name, negative_example.name]\n",
    "\n",
    "def predict_with_few_shot(row, examples):\n",
    "    \"\"\"Make prediction using few-shot learning with better prompting\"\"\"\n",
    "    prompt = f\"\"\"As a medical AI specialized in stroke prediction, analyze the following patient data:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Now evaluate this new patient:\n",
    "- Gender: {row['gender']}\n",
    "- Age: {int(row['age'])}\n",
    "- Hypertension: {row['hypertension']}\n",
    "- Heart Disease: {row['heart_disease']}\n",
    "- Ever Married: {row['ever_married']}\n",
    "- Work Type: {row['work_type']}\n",
    "- Residence Type: {row['Residence_type']}\n",
    "- Average Glucose Level: {row['avg_glucose_level']:.2f}\n",
    "- BMI: {row['bmi']:.1f}\n",
    "- Smoking Status: {row['smoking_status']}\n",
    "\n",
    "Instructions:\n",
    "1. Analyze all risk factors for stroke.\n",
    "2. Key risk factors: age, hypertension, heart disease, glucose level.\n",
    "3. Compare to the examples provided.\n",
    "4. Answer with ONLY \"Stroke\" or \"No Stroke\".\n",
    "\n",
    "Your prediction:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical AI assistant specialized in stroke prediction. Answer with ONLY 'Stroke' or 'No Stroke', nothing else.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    \n",
    "    # More robust output parsing\n",
    "    output = response.content.strip().lower()\n",
    "    if \"stroke\" in output and not any(neg in output for neg in [\"no stroke\", \"no-stroke\", \"not stroke\"]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = load_data('healthcare-dataset-stroke-data.csv')\n",
    "    \n",
    "    # Create few-shot examples\n",
    "    examples, example_indices = create_few_shot_examples(df)\n",
    "    \n",
    "    # Create a more balanced test set with both positive and negative cases\n",
    "    # Remove example cases from the dataset\n",
    "    remaining_df = df.drop(example_indices)\n",
    "    \n",
    "    # Split into stroke and non-stroke cases\n",
    "    stroke_cases = remaining_df[remaining_df['stroke'] == 1]\n",
    "    non_stroke_cases = remaining_df[remaining_df['stroke'] == 0]\n",
    "    \n",
    "    # Sample equal numbers of each for testing (10 of each)\n",
    "    test_stroke = stroke_cases.sample(min(10, len(stroke_cases)))\n",
    "    test_non_stroke = non_stroke_cases.sample(min(10, len(non_stroke_cases)))\n",
    "    \n",
    "    # Combine into balanced test set\n",
    "    test_df = pd.concat([test_stroke, test_non_stroke])\n",
    "    true_labels = test_df['stroke'].astype(int)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = []\n",
    "    for idx, row in test_df.iterrows():\n",
    "        pred = predict_with_few_shot(row, examples)\n",
    "        predictions.append(pred)\n",
    "        print(f\"Processing case {len(predictions)}/20: Actual={row['stroke']}, Predicted={pred}\")\n",
    "    \n",
    "    predictions = pd.Series(predictions, index=test_df.index)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nAccuracy: {accuracy_score(true_labels, predictions):.2%}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    \n",
    "    # Compare predictions\n",
    "    print(\"\\nDetailed Comparison:\")\n",
    "    results = pd.DataFrame({\n",
    "        'Actual': true_labels,\n",
    "        'Predicted': predictions,\n",
    "        'Match': true_labels == predictions\n",
    "    })\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93532f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
